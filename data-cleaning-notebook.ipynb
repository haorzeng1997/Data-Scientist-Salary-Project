{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cleanned and reorganized the raw data collected from Glassdoor.com for data science purpose. To prepare for model building, I list the data wrangling plan below:\n",
    "\n",
    "- Salary parsing\n",
    "    \n",
    "    The \"Salary Estimate\" was retrived as object (e.g. \\$78K-\\$133K (Glassdoor est.)). I removed     \"$\", \"K\", \"-\" and \"(Glassdoor est.)\" and only left numerical values. The salary                information will be represented by \"max_salary\", \"min_salary\" and \"avg_salary\". \n",
    "\n",
    "- Company name parsing\n",
    "\n",
    "    The \"Company\" was collected as \"_company name  company rating_\" format (e.g. Amazon 4.0).     I removed the rating element from the column which makes the Company name text-only.\n",
    "\n",
    "- Location parsing\n",
    "\n",
    "    The \"Location\" column was collcted as \"_city name, state abbreviation_\" format (e.g.    Chicago, IL). For data science purpose, I decided to only use state information and removed the city information. Including the city information in the models would potentially decrease the efficiency. Using only state information is much more reasonable and effective.\n",
    "\n",
    "- Age of Company\n",
    "\n",
    "    The \"Founded\" column has information about when the company was founded. Instead of using the specific year, I transformed that information into the age of the company.\n",
    "\n",
    "- Job description parsing\n",
    "\n",
    "    The \"Job description\" column contains text information. However, it was very long. Since the goal of this project is to estimate salary, I only extracted useful information from the column. According to _\"14 most used data science tools for 2019\" (https://data-flair.training/blogs/data-science-tools/)_, python, r studio, spark, aws, excel, sas, matlab, tableau, tensorflow are widely used by data scientists. Thus, I am interested in how many companies would include those tools in their job description pages and what the correlation between having experiences with these tools and potentially earning a higher salary.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 14 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Job Title          1000 non-null   object \n 1   Salary Estimate    1000 non-null   object \n 2   Job Description    1000 non-null   object \n 3   Rating             1000 non-null   float64\n 4   Company Name       1000 non-null   object \n 5   Location           1000 non-null   object \n 6   Headquarters       1000 non-null   int64  \n 7   Size               1000 non-null   object \n 8   Founded            1000 non-null   int64  \n 9   Type of ownership  1000 non-null   object \n 10  Industry           1000 non-null   object \n 11  Sector             1000 non-null   object \n 12  Revenue            1000 non-null   object \n 13  Competitors        1000 non-null   int64  \ndtypes: float64(1), int64(3), object(10)\nmemory usage: 109.5+ KB\n"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data-scientist-salary-data.csv\")\n",
    "# Check NULL values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary parsing\n",
    "\n",
    "The \"Salary Estimate\" was retrived as object (e.g. \\$78K-\\$133K (Glassdoor est.)). I removed  \"$\", \"K\", \"-\" and \"(Glassdoor est.)\" and only left numerical values. The salary information    will be represented by \"max_salary\", \"min_salary\" and \"avg_salary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"$\", \"K\", \"-\" and \"(Glassdoor est.)\" and only left numerical values.\n",
    "salary = df[\"Salary Estimate\"].apply(lambda x: x.split(\"(\")[0])\n",
    "salary_minusdollorandk = salary.apply(lambda x: x.replace(\"K\", \"\").replace(\"$\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"min_salary\" and \"max_salary\"\n",
    "df[\"min_salary\"] = salary_minusdollorandk.apply(lambda x: x.split(\"-\")[0])\n",
    "df[\"max_salary\"] = salary_minusdollorandk.apply(lambda x: x.split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert into int64 format\n",
    "df = df.astype({\n",
    "    \"min_salary\":\"int64\",\n",
    "    \"max_salary\":\"int64\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"avg_salary\"\n",
    "df[\"avg_salary\"] = (df[\"min_salary\"] + df[\"max_salary\"])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company name parsing\n",
    "\n",
    "The \"Company\" was collected as \"company name company rating\" format (e.g. Amazon 4.0). I removed the rating element from the column which makes the Company name text-only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rating from company name column\n",
    "df[\"company_text\"] = df.apply(lambda x: x[\"Company Name\"] if x[\"Rating\"] < 0 else x[\"Company Name\"][:-4], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location parsing\n",
    "\n",
    "The \"Location\" column was collcted as \"city name, state abbreviation\" format (e.g. Chicago, IL). For data science purpose, I decided to only use state information and removed the city information. Including the city information in the models would potentially decrease the efficiency. Using only state information is much more reasonable and effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove city info from the column\n",
    "df[\"job_state\"] = df[\"Location\"].apply(lambda x: x.split(\",\")[1].strip() if \",\" in x else x)\n",
    "# Some location cells are extracted in different formats (e.g. Virginia, United States...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace those values with standard state abbreviation\n",
    "df[\"job_state\"].replace({\n",
    "    \"United States\":\"US\",\n",
    "    \"Virginia\":\"VA\",\n",
    "    \"Massachusetts\":\"MA\",\n",
    "    \"Utah\":\"UT\",\n",
    "    \"New Jersey\":\"NJ\",\n",
    "    \"Maryland\":\"MD\",\n",
    "    \"Ohio\":\"OH\",\n",
    "    \"California\":\"CA\"\n",
    "}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Headquarters\" column is \"-1\" for all jobs. I guess Glassdoor.com made some changes and the scraper did not gather the information. So, I decided to drop the column\n",
    "df.drop(\"Headquarters\", axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age of Company\n",
    "\n",
    "The \"Founded\" column has information about when the company was founded. Instead of using the specific year, I transformed that information into the age of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = df[\"Founded\"].apply(lambda x: x if x < 0 else 2020 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "143"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# -1 means missing value, and we can see 143 companies did not report such information\n",
    "df[\"age\"][df[\"age\"]== -1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job description parsing\n",
    "\n",
    "The \"Job description\" column contains text information. However, it was very long. Since the goal of this project is to estimate salary, I only extracted useful information from the column. According to \"14 most used data science tools for 2019\" (https://data-flair.training/blogs/data-science-tools/), python, r studio, spark, aws, excel, sas, matlab, tableau, tensorflow are widely used by data scientists. Thus, I am interested in how many companies would include those tools in their job description pages and what the correlation between having experiences with these tools and potentially earning a higher salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables which indicate whether a certain tool appeared in the job description\n",
    "\n",
    "df[\"python_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"python\" in x.lower() else 0)\n",
    "df[\"r_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"r studio\" in x.lower() or \"r-studio\" in x.lower() else 0)\n",
    "df[\"spark_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"spark\" in x.lower() else 0)\n",
    "df[\"aws_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"aws\" in x.lower() else 0)\n",
    "df[\"excel_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"excel\" in x.lower() else 0)\n",
    "df[\"sas_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"sas\" in x.lower() else 0)\n",
    "df[\"matlab_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"matlab\" in x.lower() else 0)\n",
    "df[\"tableau_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"tableau\" in x.lower() else 0)\n",
    "df[\"tensorflow_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"tensorflow\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the cleaned csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data-scientist-salary-cleaned.csv\", index= False)"
   ]
  }
 ]
}