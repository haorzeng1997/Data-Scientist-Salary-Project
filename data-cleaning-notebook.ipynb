{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cleanned and reorganized the raw data collected from Glassdoor.com for data science purpose. To prepare for model building, I list the data wrangling plan below:\n",
    "\n",
    "- Salary parsing\n",
    "    \n",
    "    The \"Salary Estimate\" was retrived as object (e.g. \\$78K-\\$133K (Glassdoor est.)). I removed     \"$\", \"K\", \"-\" and \"(Glassdoor est.)\" and only left numerical values. The salary                information will be represented by \"max_salary\", \"min_salary\" and \"avg_salary\". \n",
    "\n",
    "- Company name parsing\n",
    "\n",
    "    The \"Company\" was collected as \"_company name  company rating_\" format (e.g. Amazon 4.0).     I removed the rating element from the column which makes the Company name text-only.\n",
    "\n",
    "- Location parsing\n",
    "\n",
    "    The \"Location\" column was collcted as \"_city name, state abbreviation_\" format (e.g.    Chicago, IL). For data science purpose, I decided to only use state information and removed the city information. Including the city information in the models would potentially decrease the efficiency. Using only state information is much more reasonable and effective.\n",
    "\n",
    "- Age of Company\n",
    "\n",
    "    The \"Founded\" column has information about when the company was founded. Instead of using the specific year, I transformed that information into the age of the company.\n",
    "\n",
    "- Job description parsing\n",
    "\n",
    "    The \"Job description\" column contains text information. However, it was very long. Since the goal of this project is to estimate salary, I only extracted useful information from the column. According to _\"14 most used data science tools for 2019\" (https://data-flair.training/blogs/data-science-tools/)_, python, r studio, spark, aws, excel, sas, matlab, tableau, tensorflow are widely used by data scientists. Thus, I am interested in how many companies would include those tools in their job description pages and what the correlation between having experiences with these tools and potentially earning a higher salary.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 14 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Job Title          1000 non-null   object \n 1   Salary Estimate    1000 non-null   object \n 2   Job Description    1000 non-null   object \n 3   Rating             1000 non-null   float64\n 4   Company Name       1000 non-null   object \n 5   Location           1000 non-null   object \n 6   Headquarters       1000 non-null   int64  \n 7   Size               1000 non-null   object \n 8   Founded            1000 non-null   int64  \n 9   Type of ownership  1000 non-null   object \n 10  Industry           1000 non-null   object \n 11  Sector             1000 non-null   object \n 12  Revenue            1000 non-null   object \n 13  Competitors        1000 non-null   int64  \ndtypes: float64(1), int64(3), object(10)\nmemory usage: 109.5+ KB\n"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data-scientist-salary-data.csv\")\n",
    "# Check NULL values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary parsing\n",
    "\n",
    "The \"Salary Estimate\" was retrived as object (e.g. $78K-$133K (Glassdoor est.)). I removed  \"$\", \"K\", \"-\" and \"(Glassdoor est.)\" and only left numerical values. The salary information    will be represented by \"max_salary\", \"min_salary\" and \"avg_salary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"$\", \"K\", \"-\" and \"(Glassdoor est.)\" and only left numerical values.\n",
    "salary = df[\"Salary Estimate\"].apply(lambda x: x.split(\"(\")[0])\n",
    "salary_minusdollorandk = salary.apply(lambda x: x.replace(\"K\", \"\").replace(\"$\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"min_salary\" and \"max_salary\"\n",
    "df[\"min_salary\"] = salary_minusdollorandk.apply(lambda x: x.split(\"-\")[0])\n",
    "df[\"max_salary\"] = salary_minusdollorandk.apply(lambda x: x.split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert into int64 format\n",
    "df = df.astype({\n",
    "    \"min_salary\":\"int64\",\n",
    "    \"max_salary\":\"int64\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"avg_salary\"\n",
    "df[\"avg_salary\"] = (df[\"min_salary\"] + df[\"max_salary\"])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company name parsing\n",
    "\n",
    "The \"Company\" was collected as \"company name company rating\" format (e.g. Amazon 4.0). I removed the rating element from the column which makes the Company name text-only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rating from company name column\n",
    "df[\"company_text\"] = df.apply(lambda x: x[\"Company Name\"] if x[\"Rating\"] < 0 else x[\"Company Name\"][:-4], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Amazon                    22\nAstraZeneca               17\nMITRE                     14\nPfizer                    11\nAscension                 10\n                          ..\nNextdoor                   1\nChan Zuckerberg Biohub     1\nEcolab                     1\nEntefy                     1\nOneTrust                   1\nName: company_text, Length: 488, dtype: int64"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df[\"company_text\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location parsing\n",
    "\n",
    "The \"Location\" column was collcted as \"city name, state abbreviation\" format (e.g. Chicago, IL). For data science purpose, I decided to only use state information and removed the city information. Including the city information in the models would potentially decrease the efficiency. Using only state information is much more reasonable and effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CA               254\nVA               130\nNY                89\nMA                83\nMD                53\nDC                45\nIL                39\nRemote            33\nTX                30\nUnited States     27\nWA                24\nFL                24\nNJ                23\nPA                16\nMO                12\nNC                12\nCT                10\nOH                10\nVirginia           8\nWI                 7\nOR                 6\nCO                 6\nMI                 6\nUT                 5\nSC                 5\nGA                 5\nKS                 4\nMassachusetts      4\nAL                 4\nID                 3\nIN                 3\nUtah               3\nTN                 3\nDE                 3\nOhio               1\nHI                 1\nNew Jersey         1\nNM                 1\nAZ                 1\nMN                 1\nAR                 1\nMaryland           1\nCalifornia         1\nWY                 1\nKY                 1\nName: job_state, dtype: int64"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# remove city info from the column\n",
    "df[\"job_state\"] = df[\"Location\"].apply(lambda x: x.split(\",\")[1].strip() if \",\" in x else x)\n",
    "df[\"job_state\"].value_counts()\n",
    "# Some location cells are extracted in different formats (e.g. Virginia, United States...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace those values with standard state abbreviation\n",
    "df[\"job_state\"].replace({\n",
    "    \"United States\":\"US\",\n",
    "    \"Virginia\":\"VA\",\n",
    "    \"Massachusetts\":\"MA\",\n",
    "    \"Utah\":\"UT\",\n",
    "    \"New Jersey\":\"NJ\",\n",
    "    \"Maryland\":\"MD\",\n",
    "    \"Ohio\":\"OH\",\n",
    "    \"California\":\"CA\"\n",
    "}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CA        255\nVA        138\nNY         89\nMA         87\nMD         54\nDC         45\nIL         39\nRemote     33\nTX         30\nUS         27\nFL         24\nNJ         24\nWA         24\nPA         16\nNC         12\nMO         12\nOH         11\nCT         10\nUT          8\nWI          7\nCO          6\nOR          6\nMI          6\nGA          5\nSC          5\nAL          4\nKS          4\nIN          3\nID          3\nTN          3\nDE          3\nAZ          1\nWY          1\nAR          1\nMN          1\nNM          1\nHI          1\nKY          1\nName: job_state, dtype: int64"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# check\n",
    "df[\"job_state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Headquarters\" column is \"-1\" for all jobs. I guess Glassdoor.com made some changes and the scraper did not gather the information. So, I decided to drop the column\n",
    "df.drop(\"Headquarters\", axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age of Company\n",
    "\n",
    "The \"Founded\" column has information about when the company was founded. Instead of using the specific year, I transformed that information into the age of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = df[\"Founded\"].apply(lambda x: x if x < 0 else 2020 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-1     143\n 8      39\n 26     39\n 9      36\n 10     34\n      ... \n 80      1\n 83      1\n 0       1\n 61      1\n 63      1\nName: age, Length: 110, dtype: int64"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# -1 means missing value, and we can see 143 companies did not report such information\n",
    "df[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job description parsing\n",
    "\n",
    "The \"Job description\" column contains text information. However, it was very long. Since the goal of this project is to estimate salary, I only extracted useful information from the column. According to \"14 most used data science tools for 2019\" (https://data-flair.training/blogs/data-science-tools/), python, r studio, spark, aws, excel, sas, matlab, tableau, tensorflow are widely used by data scientists. Thus, I am interested in how many companies would include those tools in their job description pages and what the correlation between having experiences with these tools and potentially earning a higher salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables which indicate whether a certain tool appeared in the job description\n",
    "\n",
    "df[\"python_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"python\" in x.lower() else 0)\n",
    "df[\"r_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"r studio\" in x.lower() or \"r-studio\" in x.lower() else 0)\n",
    "df[\"spark_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"spark\" in x.lower() else 0)\n",
    "df[\"aws_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"aws\" in x.lower() else 0)\n",
    "df[\"excel_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"excel\" in x.lower() else 0)\n",
    "df[\"sas_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"sas\" in x.lower() else 0)\n",
    "df[\"matlab_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"matlab\" in x.lower() else 0)\n",
    "df[\"tableau_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"tableau\" in x.lower() else 0)\n",
    "df[\"tensorflow_y/n\"] = df[\"Job Description\"].apply(lambda x: 1 if \"tensorflow\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the cleaned csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data-scientist-salary-cleaned.csv\", index= False)"
   ]
  }
 ]
}